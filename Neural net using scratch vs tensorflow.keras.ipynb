{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "a8528f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "6317076e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "      <th>bought_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  affordibility  bought_insurance\n",
       "0   22              1                 0\n",
       "1   25              0                 0\n",
       "2   47              1                 1\n",
       "3   52              0                 0\n",
       "4   46              1                 1"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('insurance_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "bf2fbd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28 entries, 0 to 27\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count  Dtype\n",
      "---  ------            --------------  -----\n",
      " 0   age               28 non-null     int64\n",
      " 1   affordibility     28 non-null     int64\n",
      " 2   bought_insurance  28 non-null     int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 800.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "4a73be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(df[['age','affordibility']],df.affordibility,test_size=0.2,random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "4c7f046a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "9e350de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  affordibility\n",
       "0    22              1\n",
       "13   29              0\n",
       "6    55              0\n",
       "17   58              1\n",
       "24   50              1"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62db72e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "f156c9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "0bdad345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  affordibility\n",
      "0   0.22              1\n",
      "13  0.29              0\n",
      "6   0.55              0\n",
      "17  0.58              1\n",
      "24  0.50              1\n",
      "19  0.18              1\n",
      "25  0.54              1\n",
      "16  0.25              0\n",
      "20  0.21              1\n",
      "3   0.52              0\n",
      "7   0.60              0\n",
      "1   0.25              0\n",
      "5   0.56              1\n",
      "27  0.46              1\n",
      "8   0.62              1\n",
      "18  0.19              0\n",
      "12  0.27              0\n",
      "23  0.45              1\n",
      "22  0.40              1\n",
      "15  0.55              1\n",
      "26  0.23              1\n",
      "4   0.46              1\n",
      "     age  affordibility\n",
      "2   0.47              1\n",
      "10  0.18              1\n",
      "21  0.26              0\n",
      "11  0.28              1\n",
      "14  0.49              1\n",
      "9   0.61              1\n"
     ]
    }
   ],
   "source": [
    "X_train_scale = X_train.copy()\n",
    "X_train_scale['age'] = X_train['age']/100\n",
    "print(X_train_scale)\n",
    "X_test_scale = X_test.copy()\n",
    "X_test_scale['age'] = X_test['age']/100\n",
    "print(X_test_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "a7b92017",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = keras.Sequential([\n",
    "    keras.layers.Dense(1,input_shape=(2,),activation = 'sigmoid',kernel_initializer = 'ones',bias_initializer='zeros')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "2d332fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.compile(optimizer = 'adam',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "4dbcb6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/450\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.4636 - accuracy: 0.6364\n",
      "Epoch 2/450\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4634 - accuracy: 0.6364\n",
      "Epoch 3/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4631 - accuracy: 0.6364\n",
      "Epoch 4/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4629 - accuracy: 0.6364\n",
      "Epoch 5/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4626 - accuracy: 0.6364\n",
      "Epoch 6/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4624 - accuracy: 0.6364\n",
      "Epoch 7/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4622 - accuracy: 0.6364\n",
      "Epoch 8/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4619 - accuracy: 0.6364\n",
      "Epoch 9/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4617 - accuracy: 0.6364\n",
      "Epoch 10/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4614 - accuracy: 0.6364\n",
      "Epoch 11/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4612 - accuracy: 0.6364\n",
      "Epoch 12/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4609 - accuracy: 0.6364\n",
      "Epoch 13/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4607 - accuracy: 0.6364\n",
      "Epoch 14/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4605 - accuracy: 0.6364\n",
      "Epoch 15/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4602 - accuracy: 0.6364\n",
      "Epoch 16/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4600 - accuracy: 0.6364\n",
      "Epoch 17/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4597 - accuracy: 0.6364\n",
      "Epoch 18/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4595 - accuracy: 0.6364\n",
      "Epoch 19/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4593 - accuracy: 0.6364\n",
      "Epoch 20/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4590 - accuracy: 0.6364\n",
      "Epoch 21/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4588 - accuracy: 0.6364\n",
      "Epoch 22/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4585 - accuracy: 0.6364\n",
      "Epoch 23/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4583 - accuracy: 0.6364\n",
      "Epoch 24/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4581 - accuracy: 0.6364\n",
      "Epoch 25/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4578 - accuracy: 0.6364\n",
      "Epoch 26/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4576 - accuracy: 0.6364\n",
      "Epoch 27/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4573 - accuracy: 0.6364\n",
      "Epoch 28/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4571 - accuracy: 0.6364\n",
      "Epoch 29/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4569 - accuracy: 0.6364\n",
      "Epoch 30/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4566 - accuracy: 0.6364\n",
      "Epoch 31/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4564 - accuracy: 0.6364\n",
      "Epoch 32/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4561 - accuracy: 0.6364\n",
      "Epoch 33/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4559 - accuracy: 0.6364\n",
      "Epoch 34/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4557 - accuracy: 0.6364\n",
      "Epoch 35/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4554 - accuracy: 0.6364\n",
      "Epoch 36/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4552 - accuracy: 0.6364\n",
      "Epoch 37/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4550 - accuracy: 0.6364\n",
      "Epoch 38/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4547 - accuracy: 0.6364\n",
      "Epoch 39/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4545 - accuracy: 0.6364\n",
      "Epoch 40/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4543 - accuracy: 0.6364\n",
      "Epoch 41/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4540 - accuracy: 0.6364\n",
      "Epoch 42/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4538 - accuracy: 0.6364\n",
      "Epoch 43/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4536 - accuracy: 0.6364\n",
      "Epoch 44/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4533 - accuracy: 0.6364\n",
      "Epoch 45/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4531 - accuracy: 0.6364\n",
      "Epoch 46/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4529 - accuracy: 0.6364\n",
      "Epoch 47/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4526 - accuracy: 0.6364\n",
      "Epoch 48/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4524 - accuracy: 0.6364\n",
      "Epoch 49/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4522 - accuracy: 0.6364\n",
      "Epoch 50/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4519 - accuracy: 0.6364\n",
      "Epoch 51/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4517 - accuracy: 0.6364\n",
      "Epoch 52/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4515 - accuracy: 0.6364\n",
      "Epoch 53/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4512 - accuracy: 0.6364\n",
      "Epoch 54/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4510 - accuracy: 0.6364\n",
      "Epoch 55/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4508 - accuracy: 0.6364\n",
      "Epoch 56/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4505 - accuracy: 0.6364\n",
      "Epoch 57/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4503 - accuracy: 0.6364\n",
      "Epoch 58/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4501 - accuracy: 0.6364\n",
      "Epoch 59/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4498 - accuracy: 0.6364\n",
      "Epoch 60/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4496 - accuracy: 0.6364\n",
      "Epoch 61/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4494 - accuracy: 0.6364\n",
      "Epoch 62/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4491 - accuracy: 0.6364\n",
      "Epoch 63/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4489 - accuracy: 0.6364\n",
      "Epoch 64/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4487 - accuracy: 0.6364\n",
      "Epoch 65/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4485 - accuracy: 0.6364\n",
      "Epoch 66/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4482 - accuracy: 0.6364\n",
      "Epoch 67/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4480 - accuracy: 0.6364\n",
      "Epoch 68/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4478 - accuracy: 0.6364\n",
      "Epoch 69/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4475 - accuracy: 0.6364\n",
      "Epoch 70/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4473 - accuracy: 0.6364\n",
      "Epoch 71/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4471 - accuracy: 0.6364\n",
      "Epoch 72/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4469 - accuracy: 0.6364\n",
      "Epoch 73/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4466 - accuracy: 0.6364\n",
      "Epoch 74/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4464 - accuracy: 0.6364\n",
      "Epoch 75/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4462 - accuracy: 0.6364\n",
      "Epoch 76/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4460 - accuracy: 0.6364\n",
      "Epoch 77/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4457 - accuracy: 0.6364\n",
      "Epoch 78/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4455 - accuracy: 0.6364\n",
      "Epoch 79/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4453 - accuracy: 0.6364\n",
      "Epoch 80/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4451 - accuracy: 0.6364\n",
      "Epoch 81/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4448 - accuracy: 0.6364\n",
      "Epoch 82/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4446 - accuracy: 0.6364\n",
      "Epoch 83/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4444 - accuracy: 0.6364\n",
      "Epoch 84/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4442 - accuracy: 0.6364\n",
      "Epoch 85/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4439 - accuracy: 0.6364\n",
      "Epoch 86/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4437 - accuracy: 0.6364\n",
      "Epoch 87/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4435 - accuracy: 0.6364\n",
      "Epoch 88/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4433 - accuracy: 0.6364\n",
      "Epoch 89/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4430 - accuracy: 0.6364\n",
      "Epoch 90/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4428 - accuracy: 0.6364\n",
      "Epoch 91/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4426 - accuracy: 0.6364\n",
      "Epoch 92/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4424 - accuracy: 0.6364\n",
      "Epoch 93/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4421 - accuracy: 0.6364\n",
      "Epoch 94/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4419 - accuracy: 0.6364\n",
      "Epoch 95/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4417 - accuracy: 0.6364\n",
      "Epoch 96/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4415 - accuracy: 0.6364\n",
      "Epoch 97/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4413 - accuracy: 0.6364\n",
      "Epoch 98/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4410 - accuracy: 0.6364\n",
      "Epoch 99/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4408 - accuracy: 0.6364\n",
      "Epoch 100/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4406 - accuracy: 0.6364\n",
      "Epoch 101/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4404 - accuracy: 0.6364\n",
      "Epoch 102/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4402 - accuracy: 0.6364\n",
      "Epoch 103/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4399 - accuracy: 0.6364\n",
      "Epoch 104/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4397 - accuracy: 0.6364\n",
      "Epoch 105/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4395 - accuracy: 0.6364\n",
      "Epoch 106/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4393 - accuracy: 0.6364\n",
      "Epoch 107/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4391 - accuracy: 0.6364\n",
      "Epoch 108/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4388 - accuracy: 0.6364\n",
      "Epoch 109/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4386 - accuracy: 0.6364\n",
      "Epoch 110/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4384 - accuracy: 0.6364\n",
      "Epoch 111/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4382 - accuracy: 0.6364\n",
      "Epoch 112/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4380 - accuracy: 0.6364\n",
      "Epoch 113/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4378 - accuracy: 0.6364\n",
      "Epoch 114/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4375 - accuracy: 0.6364\n",
      "Epoch 115/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4373 - accuracy: 0.6364\n",
      "Epoch 116/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4371 - accuracy: 0.6364\n",
      "Epoch 117/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4369 - accuracy: 0.6364\n",
      "Epoch 118/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4367 - accuracy: 0.6364\n",
      "Epoch 119/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4365 - accuracy: 0.6364\n",
      "Epoch 120/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4362 - accuracy: 0.6364\n",
      "Epoch 121/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4360 - accuracy: 0.6364\n",
      "Epoch 122/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4358 - accuracy: 0.6364\n",
      "Epoch 123/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4356 - accuracy: 0.6364\n",
      "Epoch 124/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4354 - accuracy: 0.6364\n",
      "Epoch 125/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4352 - accuracy: 0.6364\n",
      "Epoch 126/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4350 - accuracy: 0.6364\n",
      "Epoch 127/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4347 - accuracy: 0.6364\n",
      "Epoch 128/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4345 - accuracy: 0.6364\n",
      "Epoch 129/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4343 - accuracy: 0.6364\n",
      "Epoch 130/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4341 - accuracy: 0.6364\n",
      "Epoch 131/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4339 - accuracy: 0.6364\n",
      "Epoch 132/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4337 - accuracy: 0.6364\n",
      "Epoch 133/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4335 - accuracy: 0.6364\n",
      "Epoch 134/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4332 - accuracy: 0.6364\n",
      "Epoch 135/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4330 - accuracy: 0.6364\n",
      "Epoch 136/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4328 - accuracy: 0.6364\n",
      "Epoch 137/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4326 - accuracy: 0.6364\n",
      "Epoch 138/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4324 - accuracy: 0.6364\n",
      "Epoch 139/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4322 - accuracy: 0.6364\n",
      "Epoch 140/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4320 - accuracy: 0.6364\n",
      "Epoch 141/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4318 - accuracy: 0.6364\n",
      "Epoch 142/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4315 - accuracy: 0.6364\n",
      "Epoch 143/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4313 - accuracy: 0.6364\n",
      "Epoch 144/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4311 - accuracy: 0.6364\n",
      "Epoch 145/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4309 - accuracy: 0.6364\n",
      "Epoch 146/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4307 - accuracy: 0.6364\n",
      "Epoch 147/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4305 - accuracy: 0.6364\n",
      "Epoch 148/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4303 - accuracy: 0.6364\n",
      "Epoch 149/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4301 - accuracy: 0.6364\n",
      "Epoch 150/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4299 - accuracy: 0.6364\n",
      "Epoch 151/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4297 - accuracy: 0.6364\n",
      "Epoch 152/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4295 - accuracy: 0.6364\n",
      "Epoch 153/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4292 - accuracy: 0.6364\n",
      "Epoch 154/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4290 - accuracy: 0.6364\n",
      "Epoch 155/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4288 - accuracy: 0.6364\n",
      "Epoch 156/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4286 - accuracy: 0.6364\n",
      "Epoch 157/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4284 - accuracy: 0.6364\n",
      "Epoch 158/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4282 - accuracy: 0.6364\n",
      "Epoch 159/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4280 - accuracy: 0.6364\n",
      "Epoch 160/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4278 - accuracy: 0.6364\n",
      "Epoch 161/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4276 - accuracy: 0.6364\n",
      "Epoch 162/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4274 - accuracy: 0.6364\n",
      "Epoch 163/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4272 - accuracy: 0.6364\n",
      "Epoch 164/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4270 - accuracy: 0.6364\n",
      "Epoch 165/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4268 - accuracy: 0.6364\n",
      "Epoch 166/450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4265 - accuracy: 0.6364\n",
      "Epoch 167/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4263 - accuracy: 0.6364\n",
      "Epoch 168/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4261 - accuracy: 0.6364\n",
      "Epoch 169/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4259 - accuracy: 0.6364\n",
      "Epoch 170/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4257 - accuracy: 0.6364\n",
      "Epoch 171/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4255 - accuracy: 0.6364\n",
      "Epoch 172/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4253 - accuracy: 0.6818\n",
      "Epoch 173/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.6818\n",
      "Epoch 174/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4249 - accuracy: 0.6818\n",
      "Epoch 175/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4247 - accuracy: 0.6818\n",
      "Epoch 176/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4245 - accuracy: 0.6818\n",
      "Epoch 177/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4243 - accuracy: 0.6818\n",
      "Epoch 178/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4241 - accuracy: 0.6818\n",
      "Epoch 179/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4239 - accuracy: 0.6818\n",
      "Epoch 180/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4237 - accuracy: 0.6818\n",
      "Epoch 181/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4235 - accuracy: 0.6818\n",
      "Epoch 182/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4233 - accuracy: 0.6818\n",
      "Epoch 183/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4231 - accuracy: 0.6818\n",
      "Epoch 184/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4229 - accuracy: 0.6818\n",
      "Epoch 185/450\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4227 - accuracy: 0.6818\n",
      "Epoch 186/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4225 - accuracy: 0.6818\n",
      "Epoch 187/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4223 - accuracy: 0.6818\n",
      "Epoch 188/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4221 - accuracy: 0.6818\n",
      "Epoch 189/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4219 - accuracy: 0.6818\n",
      "Epoch 190/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4217 - accuracy: 0.6818\n",
      "Epoch 191/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4215 - accuracy: 0.6818\n",
      "Epoch 192/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4213 - accuracy: 0.6818\n",
      "Epoch 193/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4211 - accuracy: 0.6818\n",
      "Epoch 194/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4209 - accuracy: 0.6818\n",
      "Epoch 195/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4207 - accuracy: 0.6818\n",
      "Epoch 196/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4205 - accuracy: 0.6818\n",
      "Epoch 197/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4203 - accuracy: 0.6818\n",
      "Epoch 198/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4201 - accuracy: 0.6818\n",
      "Epoch 199/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4199 - accuracy: 0.6818\n",
      "Epoch 200/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4197 - accuracy: 0.6818\n",
      "Epoch 201/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4195 - accuracy: 0.6818\n",
      "Epoch 202/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4193 - accuracy: 0.6818\n",
      "Epoch 203/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4191 - accuracy: 0.6818\n",
      "Epoch 204/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4189 - accuracy: 0.6818\n",
      "Epoch 205/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4187 - accuracy: 0.6818\n",
      "Epoch 206/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4185 - accuracy: 0.6818\n",
      "Epoch 207/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4183 - accuracy: 0.6818\n",
      "Epoch 208/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4181 - accuracy: 0.6818\n",
      "Epoch 209/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4179 - accuracy: 0.6818\n",
      "Epoch 210/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4177 - accuracy: 0.6818\n",
      "Epoch 211/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4175 - accuracy: 0.6818\n",
      "Epoch 212/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4173 - accuracy: 0.6818\n",
      "Epoch 213/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4171 - accuracy: 0.6818\n",
      "Epoch 214/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.6818\n",
      "Epoch 215/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.6818\n",
      "Epoch 216/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4165 - accuracy: 0.6818\n",
      "Epoch 217/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4163 - accuracy: 0.6818\n",
      "Epoch 218/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4161 - accuracy: 0.6818\n",
      "Epoch 219/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4159 - accuracy: 0.6818\n",
      "Epoch 220/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4157 - accuracy: 0.6818\n",
      "Epoch 221/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4155 - accuracy: 0.7727\n",
      "Epoch 222/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4153 - accuracy: 0.7727\n",
      "Epoch 223/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4151 - accuracy: 0.7727\n",
      "Epoch 224/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4149 - accuracy: 0.7727\n",
      "Epoch 225/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4147 - accuracy: 0.7727\n",
      "Epoch 226/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4146 - accuracy: 0.7727\n",
      "Epoch 227/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4144 - accuracy: 0.7727\n",
      "Epoch 228/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4142 - accuracy: 0.7727\n",
      "Epoch 229/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4140 - accuracy: 0.7727\n",
      "Epoch 230/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4138 - accuracy: 0.7727\n",
      "Epoch 231/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4136 - accuracy: 0.7727\n",
      "Epoch 232/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4134 - accuracy: 0.7727\n",
      "Epoch 233/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4132 - accuracy: 0.7727\n",
      "Epoch 234/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4130 - accuracy: 0.7727\n",
      "Epoch 235/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4128 - accuracy: 0.7727\n",
      "Epoch 236/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4126 - accuracy: 0.8182\n",
      "Epoch 237/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4124 - accuracy: 0.8182\n",
      "Epoch 238/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4122 - accuracy: 0.8182\n",
      "Epoch 239/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4120 - accuracy: 0.8182\n",
      "Epoch 240/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4119 - accuracy: 0.8182\n",
      "Epoch 241/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4117 - accuracy: 0.8182\n",
      "Epoch 242/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4115 - accuracy: 0.8182\n",
      "Epoch 243/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4113 - accuracy: 0.8182\n",
      "Epoch 244/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4111 - accuracy: 0.8182\n",
      "Epoch 245/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4109 - accuracy: 0.8182\n",
      "Epoch 246/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4107 - accuracy: 0.8182\n",
      "Epoch 247/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4105 - accuracy: 0.8182\n",
      "Epoch 248/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8182\n",
      "Epoch 249/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4101 - accuracy: 0.8182\n",
      "Epoch 250/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4099 - accuracy: 0.8182\n",
      "Epoch 251/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4098 - accuracy: 0.8182\n",
      "Epoch 252/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4096 - accuracy: 0.8636\n",
      "Epoch 253/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4094 - accuracy: 0.8636\n",
      "Epoch 254/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4092 - accuracy: 0.8636\n",
      "Epoch 255/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4090 - accuracy: 0.8636\n",
      "Epoch 256/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4088 - accuracy: 0.8636\n",
      "Epoch 257/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4086 - accuracy: 0.8636\n",
      "Epoch 258/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4084 - accuracy: 0.8636\n",
      "Epoch 259/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4082 - accuracy: 0.8636\n",
      "Epoch 260/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4080 - accuracy: 0.8636\n",
      "Epoch 261/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4079 - accuracy: 0.8636\n",
      "Epoch 262/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4077 - accuracy: 0.8636\n",
      "Epoch 263/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4075 - accuracy: 0.8636\n",
      "Epoch 264/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4073 - accuracy: 0.8636\n",
      "Epoch 265/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4071 - accuracy: 0.8636\n",
      "Epoch 266/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4069 - accuracy: 0.8636\n",
      "Epoch 267/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4067 - accuracy: 0.8636\n",
      "Epoch 268/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4065 - accuracy: 0.8636\n",
      "Epoch 269/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4064 - accuracy: 0.8636\n",
      "Epoch 270/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4062 - accuracy: 0.8636\n",
      "Epoch 271/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4060 - accuracy: 0.8636\n",
      "Epoch 272/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4058 - accuracy: 0.8636\n",
      "Epoch 273/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4056 - accuracy: 0.8636\n",
      "Epoch 274/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4054 - accuracy: 0.8636\n",
      "Epoch 275/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4052 - accuracy: 0.8636\n",
      "Epoch 276/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4051 - accuracy: 0.8636\n",
      "Epoch 277/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4049 - accuracy: 0.8636\n",
      "Epoch 278/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4047 - accuracy: 0.8636\n",
      "Epoch 279/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4045 - accuracy: 0.8636\n",
      "Epoch 280/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4043 - accuracy: 0.8636\n",
      "Epoch 281/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4041 - accuracy: 0.8636\n",
      "Epoch 282/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4039 - accuracy: 0.8636\n",
      "Epoch 283/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4038 - accuracy: 0.8636\n",
      "Epoch 284/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4036 - accuracy: 0.8636\n",
      "Epoch 285/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4034 - accuracy: 0.8636\n",
      "Epoch 286/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4032 - accuracy: 0.8636\n",
      "Epoch 287/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4030 - accuracy: 0.8636\n",
      "Epoch 288/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4028 - accuracy: 0.8636\n",
      "Epoch 289/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4027 - accuracy: 0.8636\n",
      "Epoch 290/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4025 - accuracy: 0.8636\n",
      "Epoch 291/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4023 - accuracy: 0.8636\n",
      "Epoch 292/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4021 - accuracy: 0.8636\n",
      "Epoch 293/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4019 - accuracy: 0.8636\n",
      "Epoch 294/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4017 - accuracy: 0.8636\n",
      "Epoch 295/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4016 - accuracy: 0.8636\n",
      "Epoch 296/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4014 - accuracy: 0.8636\n",
      "Epoch 297/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4012 - accuracy: 0.8636\n",
      "Epoch 298/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4010 - accuracy: 0.8636\n",
      "Epoch 299/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4008 - accuracy: 0.8636\n",
      "Epoch 300/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4006 - accuracy: 0.8636\n",
      "Epoch 301/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4005 - accuracy: 0.8636\n",
      "Epoch 302/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4003 - accuracy: 0.8636\n",
      "Epoch 303/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4001 - accuracy: 0.8636\n",
      "Epoch 304/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3999 - accuracy: 0.8636\n",
      "Epoch 305/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3997 - accuracy: 0.8636\n",
      "Epoch 306/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3995 - accuracy: 0.8636\n",
      "Epoch 307/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3994 - accuracy: 0.8636\n",
      "Epoch 308/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3992 - accuracy: 0.8636\n",
      "Epoch 309/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3990 - accuracy: 0.8636\n",
      "Epoch 310/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3988 - accuracy: 0.8636\n",
      "Epoch 311/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3986 - accuracy: 0.8636\n",
      "Epoch 312/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3985 - accuracy: 0.8636\n",
      "Epoch 313/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3983 - accuracy: 0.8636\n",
      "Epoch 314/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3981 - accuracy: 0.8636\n",
      "Epoch 315/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3979 - accuracy: 0.8636\n",
      "Epoch 316/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3977 - accuracy: 0.8636\n",
      "Epoch 317/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3976 - accuracy: 0.8636\n",
      "Epoch 318/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3974 - accuracy: 0.8636\n",
      "Epoch 319/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3972 - accuracy: 0.8636\n",
      "Epoch 320/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3970 - accuracy: 0.8636\n",
      "Epoch 321/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3968 - accuracy: 0.8636\n",
      "Epoch 322/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3967 - accuracy: 0.8636\n",
      "Epoch 323/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3965 - accuracy: 0.8636\n",
      "Epoch 324/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3963 - accuracy: 0.8636\n",
      "Epoch 325/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3961 - accuracy: 0.8636\n",
      "Epoch 326/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3960 - accuracy: 0.8636\n",
      "Epoch 327/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3958 - accuracy: 0.8636\n",
      "Epoch 328/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3956 - accuracy: 0.8636\n",
      "Epoch 329/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3954 - accuracy: 0.8636\n",
      "Epoch 330/450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3952 - accuracy: 0.8636\n",
      "Epoch 331/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3951 - accuracy: 0.8636\n",
      "Epoch 332/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3949 - accuracy: 0.8636\n",
      "Epoch 333/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3947 - accuracy: 0.8636\n",
      "Epoch 334/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3945 - accuracy: 0.8636\n",
      "Epoch 335/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3944 - accuracy: 0.8636\n",
      "Epoch 336/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3942 - accuracy: 0.8636\n",
      "Epoch 337/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3940 - accuracy: 0.8636\n",
      "Epoch 338/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3938 - accuracy: 0.8636\n",
      "Epoch 339/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3937 - accuracy: 0.8636\n",
      "Epoch 340/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3935 - accuracy: 0.8636\n",
      "Epoch 341/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3933 - accuracy: 0.8636\n",
      "Epoch 342/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3931 - accuracy: 0.8636\n",
      "Epoch 343/450\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3929 - accuracy: 0.8636\n",
      "Epoch 344/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3928 - accuracy: 0.8636\n",
      "Epoch 345/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3926 - accuracy: 0.8636\n",
      "Epoch 346/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3924 - accuracy: 0.8636\n",
      "Epoch 347/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3922 - accuracy: 0.8636\n",
      "Epoch 348/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3921 - accuracy: 0.8636\n",
      "Epoch 349/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3919 - accuracy: 0.8636\n",
      "Epoch 350/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3917 - accuracy: 0.8636\n",
      "Epoch 351/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3915 - accuracy: 0.8636\n",
      "Epoch 352/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3914 - accuracy: 0.8636\n",
      "Epoch 353/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3912 - accuracy: 0.8636\n",
      "Epoch 354/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3910 - accuracy: 0.8636\n",
      "Epoch 355/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3908 - accuracy: 0.8636\n",
      "Epoch 356/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3907 - accuracy: 0.8636\n",
      "Epoch 357/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3905 - accuracy: 0.8636\n",
      "Epoch 358/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3903 - accuracy: 0.8636\n",
      "Epoch 359/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3902 - accuracy: 0.8636\n",
      "Epoch 360/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3900 - accuracy: 0.8636\n",
      "Epoch 361/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3898 - accuracy: 0.8636\n",
      "Epoch 362/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3896 - accuracy: 0.8636\n",
      "Epoch 363/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3895 - accuracy: 0.8636\n",
      "Epoch 364/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3893 - accuracy: 0.8636\n",
      "Epoch 365/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3891 - accuracy: 0.8636\n",
      "Epoch 366/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3889 - accuracy: 0.8636\n",
      "Epoch 367/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3888 - accuracy: 0.8636\n",
      "Epoch 368/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3886 - accuracy: 0.8636\n",
      "Epoch 369/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3884 - accuracy: 0.8636\n",
      "Epoch 370/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3883 - accuracy: 0.8636\n",
      "Epoch 371/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3881 - accuracy: 0.8636\n",
      "Epoch 372/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3879 - accuracy: 0.8636\n",
      "Epoch 373/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3877 - accuracy: 0.8636\n",
      "Epoch 374/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3876 - accuracy: 0.8636\n",
      "Epoch 375/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3874 - accuracy: 0.8636\n",
      "Epoch 376/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3872 - accuracy: 0.8636\n",
      "Epoch 377/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3870 - accuracy: 0.8636\n",
      "Epoch 378/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3869 - accuracy: 0.8636\n",
      "Epoch 379/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3867 - accuracy: 0.8636\n",
      "Epoch 380/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3865 - accuracy: 0.8636\n",
      "Epoch 381/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3864 - accuracy: 0.8636\n",
      "Epoch 382/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3862 - accuracy: 0.8636\n",
      "Epoch 383/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3860 - accuracy: 0.8636\n",
      "Epoch 384/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3859 - accuracy: 0.8636\n",
      "Epoch 385/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3857 - accuracy: 0.8636\n",
      "Epoch 386/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3855 - accuracy: 0.8636\n",
      "Epoch 387/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3853 - accuracy: 0.8636\n",
      "Epoch 388/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3852 - accuracy: 0.8636\n",
      "Epoch 389/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3850 - accuracy: 0.8636\n",
      "Epoch 390/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3848 - accuracy: 0.8636\n",
      "Epoch 391/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3847 - accuracy: 0.8636\n",
      "Epoch 392/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3845 - accuracy: 0.8636\n",
      "Epoch 393/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3843 - accuracy: 0.8636\n",
      "Epoch 394/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3842 - accuracy: 0.8636\n",
      "Epoch 395/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3840 - accuracy: 0.8636\n",
      "Epoch 396/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3838 - accuracy: 0.8636\n",
      "Epoch 397/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3837 - accuracy: 0.8636\n",
      "Epoch 398/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3835 - accuracy: 0.8636\n",
      "Epoch 399/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3833 - accuracy: 0.8636\n",
      "Epoch 400/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3831 - accuracy: 0.8636\n",
      "Epoch 401/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3830 - accuracy: 0.8636\n",
      "Epoch 402/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3828 - accuracy: 0.8636\n",
      "Epoch 403/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3826 - accuracy: 0.8636\n",
      "Epoch 404/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3825 - accuracy: 0.8636\n",
      "Epoch 405/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3823 - accuracy: 0.8636\n",
      "Epoch 406/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3821 - accuracy: 0.8636\n",
      "Epoch 407/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3820 - accuracy: 0.8636\n",
      "Epoch 408/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3818 - accuracy: 0.8636\n",
      "Epoch 409/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3816 - accuracy: 0.8636\n",
      "Epoch 410/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3815 - accuracy: 0.8636\n",
      "Epoch 411/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3813 - accuracy: 0.8636\n",
      "Epoch 412/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3811 - accuracy: 0.8636\n",
      "Epoch 413/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3810 - accuracy: 0.8636\n",
      "Epoch 414/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3808 - accuracy: 0.8636\n",
      "Epoch 415/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3806 - accuracy: 0.8636\n",
      "Epoch 416/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3805 - accuracy: 0.8636\n",
      "Epoch 417/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3803 - accuracy: 0.8636\n",
      "Epoch 418/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3801 - accuracy: 0.8636\n",
      "Epoch 419/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3800 - accuracy: 0.9091\n",
      "Epoch 420/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3798 - accuracy: 0.9091\n",
      "Epoch 421/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3796 - accuracy: 0.9091\n",
      "Epoch 422/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3795 - accuracy: 0.9091\n",
      "Epoch 423/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3793 - accuracy: 0.9091\n",
      "Epoch 424/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3791 - accuracy: 0.9091\n",
      "Epoch 425/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3790 - accuracy: 0.9091\n",
      "Epoch 426/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3788 - accuracy: 0.9091\n",
      "Epoch 427/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3786 - accuracy: 0.9091\n",
      "Epoch 428/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3785 - accuracy: 0.9091\n",
      "Epoch 429/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3783 - accuracy: 0.9091\n",
      "Epoch 430/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3782 - accuracy: 0.9091\n",
      "Epoch 431/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3780 - accuracy: 0.9091\n",
      "Epoch 432/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3778 - accuracy: 0.9091\n",
      "Epoch 433/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3777 - accuracy: 0.9091\n",
      "Epoch 434/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3775 - accuracy: 0.9091\n",
      "Epoch 435/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3773 - accuracy: 0.9091\n",
      "Epoch 436/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3772 - accuracy: 0.9091\n",
      "Epoch 437/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3770 - accuracy: 0.9091\n",
      "Epoch 438/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3768 - accuracy: 0.9091\n",
      "Epoch 439/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3767 - accuracy: 0.9091\n",
      "Epoch 440/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3765 - accuracy: 0.9545\n",
      "Epoch 441/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3764 - accuracy: 0.9545\n",
      "Epoch 442/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3762 - accuracy: 0.9545\n",
      "Epoch 443/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3760 - accuracy: 0.9545\n",
      "Epoch 444/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3759 - accuracy: 0.9545\n",
      "Epoch 445/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3757 - accuracy: 0.9545\n",
      "Epoch 446/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3755 - accuracy: 0.9545\n",
      "Epoch 447/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3754 - accuracy: 0.9545\n",
      "Epoch 448/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3752 - accuracy: 0.9545\n",
      "Epoch 449/450\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3750 - accuracy: 0.9545\n",
      "Epoch 450/450\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3749 - accuracy: 0.9545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f6dbebd9d0>"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(X_train_scale,y_train,epochs=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "360503ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 560ms/step - loss: 0.2924 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2923941910266876, 1.0]"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.evaluate(X_test_scale,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "9ef767cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  affordibility\n",
       "2   0.47              1\n",
       "10  0.18              1\n",
       "21  0.26              0\n",
       "11  0.28              1\n",
       "14  0.49              1\n",
       "9   0.61              1"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "ee99dcd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F6DBEFA8E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 680ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.80090123],\n",
       "       [0.7689195 ],\n",
       "       [0.4499167 ],\n",
       "       [0.7803384 ],\n",
       "       [0.80297935],\n",
       "       [0.81510425]], dtype=float32)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.predict(X_test_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "c62f4712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.6541948],\n",
       "        [1.4555631]], dtype=float32),\n",
       " array([-0.3710979], dtype=float32))"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef,intercept = model5.get_weights()\n",
    "coef,intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "bd0b0840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999847700205"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "sigmoid(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "92cc8224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.3710979], dtype=float32)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "66aac14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_fuc(age,afford):\n",
    "    y_new=(age*coef[0])+(afford*coef[1]) + intercept\n",
    "    return sigmoid(y_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "930217a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8009013], dtype=float32)"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_fuc(.47,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "99ab4126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(y_test,y_pred):\n",
    "    eps=1e-15\n",
    "    total_error = 0\n",
    "    y_ne_p = [max(i,eps) for i in (y_pred) ]\n",
    "    y_ne_p =[min(i,1-eps) for i in y_ne_p]\n",
    "    y_ne_p = np.array(y_ne_p)\n",
    "    return  -np.mean(y_test*np.log(y_ne_p)+(1-y_test)*np.log(1-y_ne_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "801d11be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ournn:\n",
    "    def __init__(self):\n",
    "        self.w1 = 1\n",
    "        self.w2 = 1\n",
    "        self.b = 0\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        Y_pred = self.w1*X_test['age']+self.w2*X_test['affordibility'] + self.b\n",
    "        return sigmoid(Y_pred)\n",
    "        \n",
    "        \n",
    "    def gradient_descent(self,age,affordibility,y_true,epochs,threshold):\n",
    "        w1 =1\n",
    "        w2= 1\n",
    "        b= 0\n",
    "        rate = 0.5\n",
    "        n=len(age)\n",
    "        c=10\n",
    "    \n",
    "        for i in range(epochs):\n",
    "            y1_new = w1*age + w2*affordibility + b\n",
    "            y_pred = sigmoid(y1_new)\n",
    "            \n",
    "            a = log_loss(y_train,y_pred)\n",
    "            \n",
    "            w1d = (1/n)*np.dot(np.transpose(age) ,(y_pred-y_train))\n",
    "            w2d = (1/n)*np.dot(np.transpose(affordibility) ,(y_pred-y_train))\n",
    "            \n",
    "            bias_d = np.mean(y1_new-y_train)\n",
    "            \n",
    "            w1 = w1- rate*w1d\n",
    "            w2 = w2- rate*w2d\n",
    "            \n",
    "            b = b - rate*bias_d\n",
    "            \n",
    "            print(f\"Epoch:{i}, w1:{w1}, w2:{w2}, bias{b}, loss:{a}\")\n",
    "            if a <= threshold:\n",
    "                break\n",
    "        return w1,w2,b\n",
    "        \n",
    "    def fit(self,x,y,epochs,loss_threshold):\n",
    "        self.w1, self.w2, self.b = self.gradient_descent(X_train_scale['age'],X_train_scale['affordibility'],y,epochs,loss_threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "718b60b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(age,affordibility,epochs,y_true,threshold):\n",
    "    w1 =1\n",
    "    w2= 1\n",
    "    b= 0\n",
    "    rate = 0.5\n",
    "    n=len(age)\n",
    "    c=10\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        y1_new = w1*age + w2*affordibility + b\n",
    "        y_pred = sigmoid(y1_new)\n",
    "        \n",
    "        a = log_loss(y_train,y_pred)\n",
    "        \n",
    "        w1d = (1/n)*np.dot(np.transpose(age) ,(y_pred-y_train))\n",
    "        w2d = (1/n)*np.dot(np.transpose(affordibility) ,(y_pred-y_train))\n",
    "        \n",
    "        bias_d = np.mean(y1_new-y_train)\n",
    "        \n",
    "        w1 = w1- rate*w1d\n",
    "        w2 = w2- rate*w2d\n",
    "        \n",
    "        b = b - rate*bias_d\n",
    "\n",
    "        print(f\"Epoch:{i}, w1:{w1}, w2:{w2}, bias{b}, loss:{a}\")\n",
    "        return w1,w2,b\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "97913b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009000000000000001"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.01*0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "5ce9f9cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, w1:0.9851349061974497, w2:1.0619844890308925, bias-0.20181818181818179, loss:0.4636130506450689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9851349061974497, 1.0619844890308925, -0.20181818181818179)"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(X_train_scale['age'],X_train_scale['affordibility'],1000,y_train,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "a9e0ef8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, w1:0.9851349061974497, w2:1.0619844890308925, bias-0.20181818181818179, loss:0.4636130506450689\n",
      "Epoch:1, w1:0.9767620694589888, w2:1.1315510270237485, bias-0.31944956394240565, loss:0.44021726313469595\n",
      "Epoch:2, w1:0.9715577874694086, w2:1.2039483363577563, bias-0.39871027186048236, loss:0.42450537890914236\n",
      "Epoch:3, w1:0.9679118102812923, w2:1.276849377378461, bias-0.4603258146060807, loss:0.4110716000298485\n",
      "Epoch:4, w1:0.9650865190159501, w2:1.349204581280816, bias-0.5135935472711387, loss:0.39862734636980424\n",
      "Epoch:5, w1:0.9627510834906808, w2:1.4205667380735627, bias-0.5626793287899571, loss:0.38683046616794226\n",
      "Epoch:6, w1:0.9607579315625934, w2:1.4907604400055416, bias-0.609457026995595, loss:0.3755674287235074\n",
      "Epoch:7, w1:0.9590407692972288, w2:1.559730387198094, bias-0.6547779815058297, loss:0.36478650800577017\n",
      "Epoch:8, w1:0.9575689805486959, w2:1.6274735503164588, bias-0.6990368873922946, loss:0.3544554433207839\n",
      "Epoch:9, w1:0.9563274174957417, w2:1.6940091601200873, bias-0.7424239494166665, loss:0.3445492603803129\n",
      "Epoch:10, w1:0.9553074922430824, w2:1.7593654973711004, bias-0.785037331732047, loss:0.33504629115715673\n",
      "Epoch:11, w1:0.954503274239406, w2:1.8235740993875669, bias-0.8269333816458866, loss:0.32592673027816005\n",
      "Epoch:12, w1:0.9539098000997485, w2:1.886667234144775, bias-0.8681491105200311, loss:0.31717206608551696\n",
      "Epoch:13, w1:0.9535223593477343, w2:1.9486768134031969, bias-0.9087122894171205, loss:0.30876483556608986\n",
      "Epoch:14, w1:0.9533362091170022, w2:2.0096339395609877, bias-0.9486460069506656, loss:0.30068850399645847\n",
      "Epoch:15, w1:0.9533464758866677, w2:2.0695687313851754, bias-0.9879707464483511, loss:0.2929273936756583\n",
      "Epoch:16, w1:0.9535481372831095, w2:2.128510272104269, bias-1.0267053492529499, loss:0.28546663242687637\n",
      "Epoch:17, w1:0.9539360367260048, w2:2.186486610743124, bias-1.0648674761840609, loss:0.27829211047811014\n",
      "Epoch:18, w1:0.9545049101655214, w2:2.243524786143094, bias-1.1024738416495454, loss:0.2713904413435994\n",
      "Epoch:19, w1:0.9552494158909083, w2:2.299650860149602, bias-1.1395403437400715, loss:0.26474892505827796\n",
      "Epoch:20, w1:0.9561641635918874, w2:2.3548899539900976, bias-1.1760821458519832, loss:0.25835551316370875\n",
      "Epoch:21, w1:0.9572437411564187, w2:2.4092662852083864, bias-1.2121137349386581, loss:0.25219877523265394\n",
      "Epoch:22, w1:0.9584827387024215, w2:2.4628032040062506, bias-1.247648967796293, loss:0.24626786685571112\n",
      "Epoch:23, w1:0.9598757697819861, w2:2.51552322850436, bias-1.2827011106200785, loss:0.24055249905551665\n",
      "Epoch:24, w1:0.961417489882411, w2:2.5674480787295875, bias-1.3172828742810636, loss:0.23504290910266884\n",
      "Epoch:25, w1:0.9631026124205893, w2:2.6185987092680105, bias-1.3514064465125781, loss:0.22972983270544525\n",
      "Epoch:26, w1:0.9649259224490234, w2:2.668995340582259, bias-1.3850835216209931, loss:0.22460447754072535\n",
      "Epoch:27, w1:0.9668822882913211, w2:2.7186574890186246, bias-1.4183253280718364, loss:0.21965849808897336\n",
      "Epoch:28, w1:0.9689666713150951, w2:2.767603995541304, bias-1.45114265417882, loss:0.2148839717324411\n",
      "Epoch:29, w1:0.971174134036497, w2:2.815853053236391, bias-1.4835458720634167, loss:0.21027337607299953\n",
      "Epoch:30, w1:0.9734998467357285, w2:2.863422233630287, bias-1.5155449600215622, loss:0.2058195674241202\n",
      "Epoch:31, w1:0.975939092747993, w2:2.9103285118677515, bias-1.547149523416174, loss:0.20151576043035221\n",
      "Epoch:32, w1:0.9784872725800008, w2:2.9565882907945866, bias-1.578368814202421, loss:0.19735550876707172\n",
      "Epoch:33, w1:0.9811399069885677, w2:3.002217423989284, bias-1.6092117491838156, loss:0.1933326868731919\n",
      "Epoch:34, w1:0.983892639145134, w2:3.047231237787073, bias-1.6396869270898273, loss:0.18944147266984498\n",
      "Epoch:35, w1:0.9867412359982248, w2:3.0916445523387406, bias-1.6698026445591823, loss:0.18567633121868712\n",
      "Epoch:36, w1:0.9896815889349445, w2:3.135471701745421, bias-1.699566911107014, loss:0.1820319992743842\n",
      "Epoch:37, w1:0.9927097138325374, w2:3.178726553309327, bias-1.728987463148466, loss:0.17850347068694977\n",
      "Epoch:38, w1:0.9958217505818079, w2:3.2214225259390856, bias-1.758071777146131, loss:0.17508598261088293\n",
      "Epoch:39, w1:0.9990139621557365, w2:3.2635726077470317, bias-1.7868270819438303, loss:0.17177500247944802\n",
      "Epoch:40, w1:1.0022827332889044, w2:3.3051893728744695, bias-1.815260370344674, loss:0.16856621570392896\n",
      "Epoch:41, w1:1.0056245688263092, w2:3.34628499757957, bias-1.8433784099870651, loss:0.16545551405923353\n",
      "Epoch:42, w1:1.009036091793758, w2:3.386871275621224, bias-1.8711877535683419, loss:0.162438984718809\n",
      "Epoch:43, w1:1.0125140412362297, w2:3.426959632970853, bias-1.8986947484620278, loss:0.15951289990342896\n",
      "Epoch:44, w1:1.0160552698653502, w2:3.466561141882862, bias-1.9259055457712335, loss:0.1566737071100124\n",
      "Epoch:45, w1:1.0196567415523792, w2:3.5056865343531336, bias-1.9528261088575343, loss:0.15391801988822174\n",
      "Epoch:46, w1:1.023315528698834, w2:3.5443462149937175, bias-1.9794622213816988, loss:0.15124260913414822\n",
      "Epoch:47, w1:1.0270288095130267, w2:3.582550273350622, bias-2.005819494889888, loss:0.1486443948719235\n",
      "Epoch:48, w1:1.0307938652173234, w2:3.6203084956904523, bias-2.031903375976407, loss:0.14612043849558343\n",
      "Epoch:49, w1:1.0346080772078363, w2:3.657630376280461, bias-2.0577191530517527, loss:0.14366793544495232\n",
      "Epoch:50, w1:1.038468924185468, w2:3.694525128185484, bias-2.0832719627425136, loss:0.1412842082907121\n",
      "Epoch:51, w1:1.0423739792747457, w2:3.731001693604139, bias-2.1085667959477052, loss:0.13896670020515914\n",
      "Epoch:52, w1:1.046320907144651, w2:3.767068753765649, bias-2.1336085035742545, loss:0.1367129687964409\n",
      "Epoch:53, w1:1.050307461143677, w2:3.802734738407636, bias-2.1584018019726634, loss:0.13452068028529524\n",
      "Epoch:54, w1:1.0543314804595685, w2:3.8380078348542908, bias-2.1829512780923035, loss:0.1323876040044936\n",
      "Epoch:55, w1:1.0583908873126435, w2:3.872895996713399, bias-2.207261394374357, loss:0.1303116072023097\n",
      "Epoch:56, w1:1.0624836841901921, w2:3.907406952209827, bias-2.2313364933990845, loss:0.1282906501324026\n",
      "Epoch:57, w1:1.066607951128222, w2:3.9415482121722296, bias-2.2551808023028714, loss:0.12632278141351883\n",
      "Epoch:58, w1:1.0707618430457297, w2:3.975327077688948, bias-2.278798436979386, loss:0.12440613364337705\n",
      "Epoch:59, w1:1.0749435871357125, w2:4.008750647448281, bias-2.302193406078133, loss:0.12253891925201107\n",
      "Epoch:60, w1:1.0791514803162925, w2:4.0418258247775976, bias-2.3253696148127267, loss:0.12071942658071068\n",
      "Epoch:61, w1:1.0833838867445829, w2:4.074559324395056, bias-2.3483308685903417, loss:0.11894601617351216\n",
      "Epoch:62, w1:1.0876392353952715, w2:4.1069576788870235, bias-2.371080876472959, loss:0.11721711726896125\n",
      "Epoch:63, w1:1.0919160177053335, w2:4.139027244923659, bias-2.3936232544803056, loss:0.11553122448059834\n",
      "Epoch:64, w1:1.0962127852857873, w2:4.170774209224531, bias-2.415961528743666, loss:0.11388689465529972\n",
      "Epoch:65, w1:1.100528147700981, w2:4.202204594285544, bias-2.4380991385191333, loss:0.112282743899255\n",
      "Epoch:66, w1:1.1048607703155247, w2:4.233324263877923, bias-2.460039439068256, loss:0.11071744476196846\n",
      "Epoch:67, w1:1.1092093722086667, w2:4.2641389283294675, bias-2.481785704413509, loss:0.10918972356924445\n",
      "Epoch:68, w1:1.1135727241556366, w2:4.294654149597815, bias-2.5033411299755164, loss:0.1076983578966564\n",
      "Epoch:69, w1:1.11794964667525, w2:4.324875346144958, bias-2.5247088350984734, loss:0.10624217417550462\n",
      "Epoch:70, w1:1.12233900814287, w2:4.354807797621824, bias-2.545891865469819, loss:0.10482004542374529\n",
      "Epoch:71, w1:1.1267397229676588, w2:4.38445664937132, bias-2.566893195439778, loss:0.10343088909482051\n",
      "Epoch:72, w1:1.1311507498329194, w2:4.413826916757805, bias-2.587715730246055, loss:0.10207366503774035\n",
      "Epoch:73, w1:1.1355710899982103, w2:4.4429234893305996, bias-2.6083623081486094, loss:0.1007473735621634\n",
      "Epoch:74, w1:1.1399997856618325, w2:4.471751134828771, bias-2.6288357024791345, loss:0.09945105360259276\n"
     ]
    }
   ],
   "source": [
    "custom_model = ournn()\n",
    "custom_model.fit(X_train_scale, y_train,epochs = 1000, loss_threshold = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "fee42dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     0.915190\n",
       "10    0.885757\n",
       "21    0.088472\n",
       "11    0.896795\n",
       "14    0.916943\n",
       "9     0.926785\n",
       "dtype: float64"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model.predict(X_test_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "a4550539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 198ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9957043 ],\n",
       "       [0.99407023],\n",
       "       [0.00718474],\n",
       "       [0.99469376],\n",
       "       [0.9957988 ],\n",
       "       [0.99632406]], dtype=float32)"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "11d94b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     1\n",
       "10    1\n",
       "21    0\n",
       "11    1\n",
       "14    1\n",
       "9     1\n",
       "Name: affordibility, dtype: int64"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3754f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
