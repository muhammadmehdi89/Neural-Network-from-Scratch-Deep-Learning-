{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c6689176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b468d066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [\n",
    "    [1,2,3,2.5],\n",
    "    [2.0,5.0,-1.0,2.0],\n",
    "    [-1.5,2.7,3.3,-0.8]\n",
    "]\n",
    "\n",
    "\n",
    "w = [\n",
    "    [0.2,0.8,-0.5,1.0],\n",
    "    [0.5,-0.91,0.26,-0.5],\n",
    "    [-0.26,-0.27,0.17,0.87]\n",
    "]\n",
    "b = [2,3,0.5]\n",
    "\n",
    "output = np.array([\n",
    "    [1,0,0],\n",
    "    [0,1,0],\n",
    "    [0,1,0]    \n",
    "])\n",
    "\n",
    "\n",
    "type(w[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e817b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "#Dense layer\n",
    "class Layer_dense:\n",
    "    def __init__(self,input_shape,neuron_shape):\n",
    "        self.weights =0.1* np.random.randn(input_shape,neuron_shape)#instead of transposing again and again take weights differently from input shape\n",
    "        self.bias = 1e-10+np.zeros((1,neuron_shape))\n",
    "    #feedforward function    \n",
    "    def forward(self,inputs):\n",
    "        self.output = np.dot(inputs,self.weights)+self.bias\n",
    "\n",
    "#Relu activation\n",
    "class activation_Relu:\n",
    "    def forward(self,inputs):\n",
    "        self.output = np.maximum(0,inputs)\n",
    "\n",
    "#Sigmoid acti...\n",
    "class activation_Sigmoid:\n",
    "    def forward(self,inputs):\n",
    "        self.output = 1/(1+np.exp(-inputs))   \n",
    "\n",
    "        \n",
    "#Softmax acti...        \n",
    "class activation_Softmax:\n",
    "    def forward(self,inputs):\n",
    "        Inputs = np.max(inputs,axis = 1)\n",
    "        Size = Inputs.size\n",
    "        New_shape = Inputs.reshape(Size,1)\n",
    "        inputs = inputs - New_shape\n",
    "        exp = np.exp(inputs)\n",
    "        add = np.sum(exp,axis=1)\n",
    "        size = add.size\n",
    "        add = add.reshape(size,1)\n",
    "        self.output = exp/add\n",
    "\n",
    "        \n",
    "'''class Cost:\n",
    "    def calculate(self, output, y):\n",
    "        sample_losses = self.forward(output, y)\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        return data_loss\n",
    "'''    \n",
    "\n",
    "class Categorical_Cross:\n",
    "    def forward(self,y_pred,y_true):\n",
    "        samples = len(y_pred)\n",
    "        y_pred_clipped = np.clip(y_pred,1e-7,1-1e-7)\n",
    "        if len(y_true.shape)==1:\n",
    "            correct_values = y_pred_clipped[range(samples),y_true]\n",
    "        elif len(y_true.shape)==2:\n",
    "            correct_values = np.sum(y_pred_clipped*y_true,axis=1)\n",
    "            \n",
    "        log_loss = -np.log(correct_values)\n",
    "        return log_loss\n",
    "    def calculate(self, output, y):\n",
    "        sample_losses = self.forward(output, y)\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        return data_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "11ba8764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.01226003  0.40413105  0.23502094]\n",
      " [ 1.46036793  1.05775487  0.00828524]\n",
      " [ 0.62111461  0.38274571 -0.56107983]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.01226003, 0.40413105, 0.23502094],\n",
       "       [1.46036793, 1.05775487, 0.00828524],\n",
       "       [0.62111461, 0.38274571, 0.        ]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_01 = Layer_dense(4,3)\n",
    "layer_01.forward(inputs)\n",
    "print(layer_01.output)\n",
    "\n",
    "\n",
    "activati1 = activation_Relu()\n",
    "activati1.forward(layer_01.output)\n",
    "activati1.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8f8bc1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09787937  0.05262401 -0.02336119]\n",
      " [ 0.14669346  0.17509833  0.04100443]\n",
      " [ 0.06004041  0.06474265  0.01971665]]\n",
      "[[0.35191761 0.33634644 0.31173595]\n",
      " [0.34146982 0.35130829 0.30722189]\n",
      " [0.33724632 0.33883587 0.32391781]]\n"
     ]
    }
   ],
   "source": [
    "layer_2 = Layer_dense(3,3)\n",
    "layer_2.forward(activati1.output)\n",
    "print(layer_2.output)\n",
    "\n",
    "\n",
    "\n",
    "act = activation_Softmax()\n",
    "act.forward(layer_2.output)\n",
    "print(act.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "614a176e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0575629266129727"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = Categorical_Cross()\n",
    "loss.calculate(act.output,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3949cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
